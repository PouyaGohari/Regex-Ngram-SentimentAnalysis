# Regex-Ngram-SentimentAnalysis
This repository contains solutions to a computer assignment for a Natural Language Processing course. The assignment covers various topics including regular expressions, tokenization algorithms used in GPT and BERT, n-gram models, and their application in sentiment analysis.

## Table of Contents

- [Introduction](#introduction)
- [Assignment Details](#assignment-details)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Report](#report)
- [Usage](#usage)
- [License](#license)

## Introduction

This project is part of a Natural Language Processing course and focuses on several foundational NLP techniques:

1. **Regular Expressions**: Understanding and applying regex to solve text processing problems.
2. **Tokenization**: Exploring and applying tokenization algorithms used in GPT and BERT on a dataset.
3. **N-gram Models**: Implementing n-gram models and understanding their role in language modeling.
4. **Sentiment Analysis**: Applying n-gram models for sentiment analysis.

## Assignment Details

### Problem 1: Regular Expressions

- Getting familiar with regular expressions and their application in text processing tasks.

### Problem 2: Tokenization in GPT and BERT

- Investigating the algorithms used in GPT and BERT's tokenizers and applying these methods to a given dataset.

### Problem 3: N-gram Models

- Implementing n-gram models and exploring their use in language modeling.

### Problem 4: Sentiment Analysis with N-gram Models

- Using n-gram models for sentiment analysis to classify the sentiment of text data.

## Prerequisites

- Basic understanding of Natural Language Processing concepts like tokenizers, n-gram, and or regular expressions.
- Libraries: `nltk`, `tokenizers`, `re`

## Installation

To clone and run this repository locally:
```sh
git clone https://github.com/PouyaGohari/Regex-Ngram-SentimentAnalysis.git
cd NLP-Regex-Ngram-Tokenization
```

## Report

A comprehensive report detailing the entire process, including background information, methodology, and results, is available in the project. You can view the report [here](Report/Report.pdf).

## Usage

All the tasks, including regular expressions, tokenization, n-gram models, and sentiment analysis, are implemented in a single Jupyter notebook.
The [`notebook`](My%20codes/CA.ipynb) is organized sequentially, allowing you to work through each problem in order.

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

